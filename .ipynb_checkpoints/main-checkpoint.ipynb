{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segmentation_models_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-875fdfa2525f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msegmentation_models_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinknet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFPN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSPNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'segmentation_models_pytorch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from segmentation_models_pytorch import Unet, Linknet, FPN, PSPNet\n",
    "from torchvision.transforms import functional as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    if image.shape[0] in [1, 3]:\n",
    "        image = image[0]\n",
    "    elif image.shape[-1] in [1, 3]:\n",
    "        image = image[..., -1]\n",
    "    image = tf.to_pil_image(image)\n",
    "    image = tf.resize(image, [512, 512])\n",
    "    image = tf.to_tensor(image)\n",
    "    image = tf.normalize(image, image.mean(), image.std())\n",
    "    return image.unsqueeze(0)\n",
    "\n",
    "def predict(image, experiment_name, architecture_name, encoder, encoder_weights):\n",
    "    if architecture_name == 'Unet':\n",
    "        architecture = Unet\n",
    "    if architecture_name == 'Linknet':\n",
    "        architecture = Linknet\n",
    "    if architecture_name == 'FPN':\n",
    "        architecture = FPN\n",
    "    if architecture_name == 'PSPNet':\n",
    "        architecture = PSPNet\n",
    "    model = architecture(encoder, encoder_weights=encoder_weights, activation='sigmoid', in_channels=1).to('cpu')\n",
    "    checkpoint = f'https://github.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-in-ct/releases/latest/download/{experiment_name}-{architecture_name}-{encoder}-{encoder_weights}.pt'\n",
    "    model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, map_location='cpu'))\n",
    "    model.eval()\n",
    "    image = preprocess(image)\n",
    "    prediction = model(image)\n",
    "    prediction = prediction[0, 0].detach().numpy()\n",
    "    prediction = prediction > 0.5\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('./covid-19-pneumonia-4.jpg')\n",
    "image = np.asarray(image)\n",
    "experiment_name = 'lesion-segmentation-a' # or 'lung-segmentation'\n",
    "architecture_name = 'PSPNet' # or any of 'Unet', 'Linknet', 'FPN'\n",
    "encoder = 'mobilenet_v2' # or any of 'vgg11', 'vgg13', 'vgg19', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'resnext50_32x4d', 'dpn68', 'dpn98', 'mobilenet_v2', 'xception', 'inceptionv4', 'efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', 'efficientnet-b3', 'efficientnet-b4', 'efficientnet-b5', 'efficientnet-b6'\n",
    "encoder_weights = 'imagenet' # or 'None'\n",
    "prediction = predict(image, experiment_name, architecture_name, encoder, encoder_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.subplot(121)\n",
    "plt.imshow(image, cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "plt.subplot(122)\n",
    "plt.imshow(image, cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "plt.imshow(prediction, cmap='Reds', alpha=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
