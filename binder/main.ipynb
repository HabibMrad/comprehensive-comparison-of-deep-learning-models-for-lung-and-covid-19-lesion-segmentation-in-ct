{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib inline\nimport torch\nimport numpy as np\n\nfrom ipywidgets import interact\nfrom ipywidgets.widgets import Dropdown\nfrom matplotlib import pyplot as plt\nfrom segmentation_models_pytorch import Unet, Linknet, FPN, PSPNet\nfrom torchvision.transforms import functional as tf\nfrom PIL import Image\nplt.ion()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def preprocess(image):\n    if image.shape[0] in [1, 3]:\n        image = image[0]\n    elif image.shape[-1] in [1, 3]:\n        image = image[..., -1]\n    image = tf.to_pil_image(image)\n    image = tf.resize(image, [512, 512])\n    image = tf.to_tensor(image)\n    image = tf.normalize(image, image.mean(), image.std())\n    return image.unsqueeze(0)\n\ndef predict(image, experiment_name, architecture_name, encoder, encoder_weights):\n    if architecture_name == 'Unet':\n        architecture = Unet\n    if architecture_name == 'Linknet':\n        architecture = Linknet\n    if architecture_name == 'FPN':\n        architecture = FPN\n    if architecture_name == 'PSPNet':\n        architecture = PSPNet\n    model = architecture(encoder, encoder_weights=encoder_weights, activation='sigmoid', in_channels=1).to('cpu')\n    checkpoint = f'https://github.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-in-ct/releases/latest/download/{experiment_name}-{architecture_name}-{encoder}-{encoder_weights}.pt'\n    model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, map_location='cpu'))\n    model.eval()\n    image = preprocess(image)\n    prediction = model(image)\n    prediction = prediction[0, 0].detach().numpy()\n    prediction = prediction > 0.5\n    return prediction\n\nimage = Image.open('./covid-19-pneumonia-4.jpg')\nimage = np.asarray(image)\nexperiment_name_list = ['lung-segmentation', 'lesion-segmentation-a']\narchitecture_name = ['Unet', 'Linknet', 'FPN', 'PSPNet']\nencoder = ['vgg11', 'vgg13', 'vgg19', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'resnext50_32x4d', 'dpn68', 'dpn98', 'mobilenet_v2', 'xception', 'inceptionv4', 'efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', 'efficientnet-b3', 'efficientnet-b4', 'efficientnet-b5', 'efficientnet-b6']\nencoder_weights = ['None', 'imagenet']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def predict_and_plot(experiment_name, architecture_name, encoder, encoder_weights):\n    prediction = predict(image, experiment_name, architecture_name, encoder, encoder_weights)\n    plt.subplot(121)\n    plt.imshow(image, cmap='gray', vmin=-1.5, vmax=1.5)\n    plt.subplot(122)\n    plt.imshow(image, cmap='gray', vmin=-1.5, vmax=1.5)\n    plt.imshow(prediction, cmap='Reds', alpha=0.5)\n    \np = interact(predict_and_plot, experiment_name=Dropdown(options=experiment_name_list), architecture_name=Dropdown(options=architecture_name_list), encoder=Dropdown(options=encoder_list), encoder_weights=(options=encoder_weights_list))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}