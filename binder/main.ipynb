{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\nfrom segmentation_models_pytorch import Unet, Linknet, FPN, PSPNet\nfrom torchvision.transforms import functional as tf\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(image):\n    if image.shape[0] in [1, 3]:\n        image = image[0]\n    elif image.shape[-1] in [1, 3]:\n        image = image[..., -1]\n    image = tf.to_pil_image(image)\n    image = tf.resize(image, [512, 512])\n    image = tf.to_tensor(image)\n    image = tf.normalize(image, image.mean(), image.std())\n    return image.unsqueeze(0)\n\ndef predict(image, experiment_name, architecture_name, encoder, encoder_weights):\n    if architecture_name == 'Unet':\n        architecture = Unet\n    if architecture_name == 'Linknet':\n        architecture = Linknet\n    if architecture_name == 'FPN':\n        architecture = FPN\n    if architecture_name == 'PSPNet':\n        architecture = PSPNet\n    model = architecture(encoder, encoder_weights=encoder_weights, activation='sigmoid', in_channels=1).to('cpu')\n    checkpoint = f'https://github.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-in-ct/releases/latest/download/{experiment_name}-{architecture_name}-{encoder}-{encoder_weights}.pt'\n    model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, map_location='cpu'))\n    model.eval()\n    image = preprocess(image)\n    prediction = model(image)\n    prediction = prediction[0, 0].detach().numpy()\n    prediction = prediction > 0.5\n    return prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = Image.open('./covid-19-pneumonia-4.jpg')\nimage = np.asarray(image)\nexperiment_name = 'lesion-segmentation-a' # or 'lung-segmentation'\narchitecture_name = 'PSPNet' # or any of 'Unet', 'Linknet', 'FPN'\nencoder = 'mobilenet_v2' # or any of 'vgg11', 'vgg13', 'vgg19', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'resnext50_32x4d', 'dpn68', 'dpn98', 'mobilenet_v2', 'xception', 'inceptionv4', 'efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', 'efficientnet-b3', 'efficientnet-b4', 'efficientnet-b5', 'efficientnet-b6'\nencoder_weights = 'imagenet' # or 'None'\nprediction = predict(image, experiment_name, architecture_name, encoder, encoder_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nplt.subplot(121)\nplt.imshow(image, cmap='gray', vmin=-1.5, vmax=1.5)\nplt.subplot(122)\nplt.imshow(image, cmap='gray', vmin=-1.5, vmax=1.5)\nplt.imshow(prediction, cmap='Reds', alpha=0.5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}