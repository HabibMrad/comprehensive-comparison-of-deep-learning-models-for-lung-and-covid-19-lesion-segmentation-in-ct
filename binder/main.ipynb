{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f1940d57e10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from ipywidgets.widgets import Dropdown\n",
    "from matplotlib import pyplot as plt\n",
    "from segmentation_models_pytorch import Unet, Linknet, FPN, PSPNet\n",
    "from torchvision.transforms import functional as tf\n",
    "from PIL import Image\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    if image.shape[0] in [1, 3]:\n",
    "        image = image[0]\n",
    "    elif image.shape[-1] in [1, 3]:\n",
    "        image = image[..., -1]\n",
    "    image = tf.to_pil_image(image)\n",
    "    image = tf.resize(image, [512, 512])\n",
    "    image = tf.to_tensor(image)\n",
    "    image = tf.normalize(image, image.mean(), image.std())\n",
    "    return image.unsqueeze(0)\n",
    "\n",
    "def predict(image, experiment_name, architecture_name, encoder, encoder_weights):\n",
    "    if architecture_name == 'Unet':\n",
    "        architecture = Unet\n",
    "    if architecture_name == 'Linknet':\n",
    "        architecture = Linknet\n",
    "    if architecture_name == 'FPN':\n",
    "        architecture = FPN\n",
    "    if architecture_name == 'PSPNet':\n",
    "        architecture = PSPNet\n",
    "    model = architecture(encoder, encoder_weights=encoder_weights, activation='sigmoid', in_channels=1).to('cpu')\n",
    "    checkpoint = f'https://github.com/pbizopoulos/comprehensive-comparison-of-deep-learning-models-for-lung-and-covid-19-lesion-segmentation-in-ct/releases/latest/download/{experiment_name}-{architecture_name}-{encoder}-{encoder_weights}.pt'\n",
    "    model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, map_location='cpu'))\n",
    "    model.eval()\n",
    "    image = preprocess(image)\n",
    "    prediction = model(image)\n",
    "    prediction = prediction[0, 0].detach().numpy()\n",
    "    prediction = prediction > 0.5\n",
    "    return prediction\n",
    "\n",
    "image = Image.open('./covid-19-pneumonia-4.jpg')\n",
    "image = np.asarray(image)\n",
    "experiment_name_list = ['lung-segmentation', 'lesion-segmentation-a']\n",
    "architecture_name_list = ['Unet', 'Linknet', 'FPN', 'PSPNet']\n",
    "encoder_list = ['vgg11', 'vgg13', 'vgg19', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'resnext50_32x4d', 'dpn68', 'dpn98', 'mobilenet_v2', 'xception', 'inceptionv4', 'efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', 'efficientnet-b3', 'efficientnet-b4', 'efficientnet-b5', 'efficientnet-b6']\n",
    "encoder_weights_list = [None, 'imagenet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e9605eb5f84fff95e5d43baae26e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='experiment_name', options=('lung-segmentation', 'lesion-segmentatiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_and_plot(experiment_name, architecture_name, encoder, encoder_weights):\n",
    "    prediction = predict(image, experiment_name, architecture_name, encoder, encoder_weights)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(image, cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(image, cmap='gray', vmin=-1.5, vmax=1.5)\n",
    "    plt.imshow(prediction, cmap='Reds', alpha=0.5)\n",
    "    \n",
    "p = interact(predict_and_plot, experiment_name=Dropdown(options=experiment_name_list), architecture_name=Dropdown(options=architecture_name_list), encoder=Dropdown(options=encoder_list), encoder_weights=Dropdown(options=encoder_weights_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
